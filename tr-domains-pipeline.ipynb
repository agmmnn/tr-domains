{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"151805XTDg--dgHb3-AXJCpnWaqRhop_2","timestamp":1670874200112}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# list_docreq=[\"gov.tr\",\"bel.tr\",\"pol.tr\",\"edu.tr\",\"k12.tr\",\"av.tr\",\"dr.tr\",\"gov.ct.tr\",\"tsk.tr\"]\n","# list_nodoc=[\"com.tr\",\"net.tr\",\"org.tr\",\"biz.tr\",\"info.tr\",\"tv.tr\",\"gen.tr\",\"web.tr\",\"name.tr\",\"bbs.tr\"]\n","# list_other=[\"istanbul\",\"ist\"]\n","domain=\"bbs.tr\""],"metadata":{"id":"sounpr4tdexX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget \"https://github.com/OWASP/Amass/releases/download/v3.21.2/amass_linux_amd64.zip\"\n","!unzip \"amass_linux_amd64.zip\" -d \"/content/tools\"\n","!rm \"amass_linux_amd64.zip\"\n","\n","!wget \"https://github.com/projectdiscovery/subfinder/releases/download/v2.5.5/subfinder_2.5.5_linux_amd64.zip\"\n","!unzip \"subfinder_2.5.5_linux_amd64.zip\" -d \"/content/tools\"\n","!rm \"subfinder_2.5.5_linux_amd64.zip\"\n","\n","!wget \"https://github.com/projectdiscovery/httpx/releases/download/v1.2.5/httpx_1.2.5_linux_amd64.zip\"\n","!unzip \"httpx_1.2.5_linux_amd64.zip\" -d \"/content/tools\"\n","!rm \"httpx_1.2.5_linux_amd64.zip\""],"metadata":{"id":"Gu2GUzkIct4l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`1. Domain Enumeration`\n","\n","_Run it after uploading the config files or just delete the config commands(-config, -pc)._ "],"metadata":{"id":"J9TvbK-PQkJ-"}},{"cell_type":"code","source":["!./tools/amass_linux_amd64/amass enum -passive -d \"$domain\" -o \"$domain\".amass.txt -silent -config \"config.ini\" &> /dev/null"],"metadata":{"id":"kZFiItyNMC3z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./tools/subfinder -d $domain -o \"$domain\".subfinder.txt -all -t 20 -nW -silent -max-time 120 -timeout 6  -pc \"provider-config.yaml\" &> /dev/null"],"metadata":{"id":"q38QuhE_IkbH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`2. Merge lists, cleaning root domains`"],"metadata":{"id":"KJX02fyeQv0A"}},{"cell_type":"code","source":["# file merge\n","inputlist = []\n","inputfiles = [domain+\".amass.txt\",domain+\".subfinder.txt\"]\n","for i in inputfiles:\n","    with open(i, \"r\", encoding=\"utf-8\") as f:\n","            inputlist.extend(f.readlines())\n","print(len(inputlist))\n","# clean domains\n","itemlist = []\n","for i in inputlist:\n","    if \"xn--\" in i:\n","        continue\n","    item = i.split(f\".{domain}\")[0].split(\".\")[-1] + f\".{domain}\"\n","    if item not in itemlist:\n","        itemlist.append(item)\n","\n","# itemlist.sort()\n","print(\"total domains: \", len(itemlist))\n","with open(domain+\"_final.txt\", \"w\", encoding=\"utf-8\") as f:\n","    for i in itemlist:\n","        f.write(\"%s\\n\" % i)"],"metadata":{"id":"ByRzWey_epu0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`3. Validating the domain list with httpx`"],"metadata":{"id":"B_CvB3nTdh2V"}},{"cell_type":"code","source":["!./tools/httpx -l \"$domain\"_final.txt -t 100 -timeout 6 -json -o \"$domain\"_final.jsonl -silent &> /dev/null"],"metadata":{"id":"vOXL7N0G3nPG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`4. Generating json file and url list from httpx output`"],"metadata":{"id":"xtnn9onyRPl8"}},{"cell_type":"code","source":["# !sed r 1.jsonl 2.jsonl > 3.jsonl"],"metadata":{"id":"boXqbi1AU4BS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","with open(domain+'_final.jsonl',encoding=\"utf-8\") as f:\n","    data = [json.loads(line) for line in f]\n","\n","print(\"total domains: \", len(data))\n","out=json.dumps(data) #.encode(\"utf-8\").decode('unicode-escape')\n","\n","with open(domain+\".json\",\"w\",encoding=\"utf-8\") as f:\n","    f.write(out)\n","\n","#json to urls.txt\n","with open(domain+\".json\",\"r\",encoding=\"utf-8\") as f:\n","  jdata=json.load(f)\n","\n","urls=[]\n","for i in jdata:\n","  item=i[\"url\"].split(\"//\")[1].split(\":\")[0]\n","  if item not in urls:\n","    urls.append(item)\n","urls.sort()\n","with open(domain+\".txt\", \"w\", encoding=\"utf-8\") as f:\n","    for i in urls:\n","        f.write(\"%s\\n\" % i)"],"metadata":{"id":"MrxsqyWp6DfJ"},"execution_count":null,"outputs":[]}]}